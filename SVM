# -*- coding: utf-8 -*-
"""
Created on Thu Feb 13 09:52:38 2020

@author: liush
"""

import time
import numpy as np
import pandas as pd
from sklearn import svm
from sklearn.metrics import f1_score
from sklearn.metrics import accuracy_score
from sklearn.model_selection import cross_val_score
from sklearn import preprocessing
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.decomposition import PCA

start = time.time()
#x_train=pd.read_csv(r'D:\Download\FYP\python\1\10_25\train.csv',index_col=0)
#y_train=pd.read_csv(r'D:\Download\FYP\python\1\10_25\train_label.csv',index_col=0)
#y_train=np.ravel(y_train)
#x_test1=pd.read_csv(r'D:\Download\FYP\python\1\10_25\test.csv',index_col=0)
#y_test1=pd.read_csv(r'D:\Download\FYP\python\1\10_25\test_label.csv',index_col=0)
#y_test1=np.ravel(y_test1)
x1=pd.read_csv(r'D:\Download\FYP\python\0data\x1.csv',index_col=0).iloc[:,:13]    
x2=pd.read_csv(r'D:\Download\FYP\python\0data\x2.csv',index_col=0).iloc[:,:13]    
x3=pd.read_csv(r'D:\Download\FYP\python\0data\x3.csv',index_col=0).iloc[:,:13]    
#x4=pd.read_csv(r'D:\Download\FYP\python\0data\x4.csv',index_col=0).iloc[:,:5]    
x5=pd.read_csv(r'D:\Download\FYP\python\0data\x5.csv',index_col=0)  
#x5=x5.multiply(math.log(x5,10))
#x=np.hstack((x1,x2,x3,x5))
x=x1
y=pd.read_csv(r'D:\Download\FYP\python\0data\y.csv',index_col=0)
y=np.ravel(y)
x_train, x_test1, y_train, y_test1 = train_test_split(x, y, test_size=0.3, shuffle = True, stratify=y)

#standardize data
sc_X = preprocessing.StandardScaler()
x_train = sc_X.fit_transform(x_train)
x_test1 = sc_X.transform(x_test1)
#
#from sklearn import datasets, cluster
#agglo = cluster.FeatureAgglomeration(n_clusters=45)
#
#agglo.fit(x_train)
#x_train = agglo.transform(x_train)
#x_test1 = agglo.transform(x_test1)

#先训练PCA模型
#PCA=PCA(n_components=9).fit(x_train)
##返回测试集和训练集降维后的数据集
#x_train_pca = PCA.transform(x_train)
#x_test_pca = PCA.transform(x_test1)
#
##载入LDA模型，设置n_components=3
#model_lda = LinearDiscriminantAnalysis(n_components=8).fit(x_train, y_train)
#x_train = model_lda.transform(x_train)
#x_test1 = model_lda.transform(x_test1)

#3.训练svm分类器
# 先使用线性核函数
#from sklearn.svm import SVC
#clas = svm.LinearSVC(class_weight = 'balanced')


clas=svm.SVC(C=13.0,kernel = "linear",class_weight = 'balanced',gamma='auto')#'linear', 'poly', 'rbf', 'sigmoid', 'precomputed' or a callable.

#clas=svm.SVC(C=2.0, kernel = "rbf")
#clas=svm.SVC(C=2,cache_size=800,class_weight='balanced',decision_function_shape='ovr',kernel='rbf') # ovr:一对多策略
#clas.fit(x_train,y_train) #ravel函数在降维时默认是行序优先

#cls=svm.LinearSVC(class_weight='balanced',max_iter=3000)
#clas.fit(x_train,y_train)
#predict=clas.predict(x_test1)
#print('准确率',accuracy_score(y_test1,predict))
##
#print("训练集：",clas.score(x_train,y_train))
#print("测试集：",clas.score(x_test1,y_test1))

#cross validate the results 
classifier=clas.fit(x_train,y_train) #ravel函数在降维时默认是行序优先
print("训练集：",clas.score(x_train,y_train))
print("测试集：",clas.score(x_test1,y_test1))


#交叉验证
#from sklearn.model_selection import ShuffleSplit
#cv = ShuffleSplit(n_splits=3, test_size=0.3, random_state=0)

#from sklearn.model_selection import StratifiedShuffleSplit
#ss=StratifiedShuffleSplit(n_splits=5,test_size=0.3,random_state=42)
#
#scores = cross_val_score(clas,x,y, cv=3)
#score_mfcc = scores.mean()
#print(str(score_mfcc))
#
#from sklearn.model_selection import cross_val_predict
#from sklearn import metrics
#
#predicted = cross_val_predict(clas, x, y, cv=5)
##predicted = predicted.mean()
##print(predicted)
#metrics.accuracy_score(y, predicted)
#print(metrics.accuracy_score(y, predicted))
#print(confusion_matrix(y_test1,predicted))
#

#print(str(k) + ' : ' +str(score_mfcc))


#scores = cross_val_score(clas, x_train, y_train, cv=5)
#print(scores)

y_pred = clas.fit(x_train, y_train).predict(x_test1) 
print('\n'+'混淆矩阵：')
print(confusion_matrix(y_test1,y_pred))
#print(confusion_matrix(y_test1,predicted))

#print('准确率',accuracy_score(y_test1,y_pred))
confusion_matrix=confusion_matrix(y_test1, y_pred, labels=None, sample_weight=None)#横为预测值

import matplotlib.pyplot as plt
labels =  ['B1-80', 'B3-80', 'B4-80','BK-PaperShuff','CF-Amy','CM-Was','Macbook_KB','TIC-fing','WA-Soft-KB']
 #labels = ['B4-80','BK-PaperShuff','CF-Amy','CM-Was','KY-Soft-KB','Macbook_KB','TIC-fing','WA-Soft-KB'] #['B1-80', 'B3-80','B4-80','BK-PaperShuff', 'CF-Amy', 'CM-Was','KY-Soft-KB','Macbook_KB','TIC-fing','WA-Soft-KB']
 
tick_marks = np.array(range(len(labels))) + 0.5
def plot_confusion_matrix(cm, title='Confusion Matrix', cmap=plt.cm.binary):

    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
    plt.title(title)#title（标题）
    plt.colorbar()
    xlocations = np.array(range(len(labels)))
    plt.xticks(xlocations, labels, rotation=45)
    plt.yticks(xlocations, labels)
    plt.ylabel('True label')#xlabel与ylabel（设置坐标轴标签）
    plt.xlabel('Predicted label')
y_true=y_test1
cm = confusion_matrix
np.set_printoptions(precision=2)
cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
#print (cm_normalized)
plt.figure(figsize=(12, 8), dpi=120)
ind_array = np.arange(len(labels))
x, y = np.meshgrid(ind_array, ind_array)
for x_val, y_val in zip(x.flatten(), y.flatten()):
    c = cm_normalized[y_val][x_val]
    if c > 0.01:
        plt.text(x_val, y_val, "%0.2f" % (c,), fontsize=12, va='center', ha='center',color="white" if c > 0.5 else "black")
plt.gca().set_xticks(tick_marks, minor=True)#xticks与yticks（设置坐标轴刻度）
plt.gca().set_yticks(tick_marks, minor=True)
plt.gca().xaxis.set_ticks_position('none')#set_ticks_position('bottom') # 将底边框置于数据坐标原点 
plt.gca().yaxis.set_ticks_position('none')
plt.grid(True, which='minor', linestyle='-')
plt.gcf().subplots_adjust(bottom=0.3)
plot_confusion_matrix(cm_normalized)#, title='20ms length 75% overlap for SVM with 4 features')
plt.show()


end = time.time()
print("循环运行时间:%.2f秒"%(end-start))
